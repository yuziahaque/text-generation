{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOUyJAUQ+PR8q6CTfc9ekb/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"qEMS8R2-t0LC","executionInfo":{"status":"ok","timestamp":1706096431355,"user_tz":-330,"elapsed":5076,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"outputs":[],"source":["#import tensorflow and other libraries\n","import os #using operating system-dependent functionality\n","import warnings #handles warnings\n","\n","warnings.filterwarnings(\"ignore\") # if there are any warning messages during the script execution, they won't be displayed.\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" #Used to control the logging behavior of TensorFlow. Setting it to \"2\" suppresses all INFO-level logs and only displays warnings and errors.\n","import time #provides time related functions\n","import numpy as np\n","import tensorflow as tf"]},{"cell_type":"code","source":["#Download the Shakespeare dataset\n","path_to_file = tf.keras.utils.get_file(\n","    \"shakespeare.txt\",\n","    \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\",\n",")\n","#tf.keras.utils.get_file function used to download files"],"metadata":{"id":"HTVG1oEyuFDh","executionInfo":{"status":"ok","timestamp":1706096431368,"user_tz":-330,"elapsed":90,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"67c17944-b793-414e-92b8-659de1685338"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1115394/1115394 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["text = open(path_to_file, \"rb\").read().decode(encoding=\"utf-8\") #rb==binary read mode    #.decode(encoding=\"utf-8\")==decoded from bytes to Unicode using the UTF-8 encoding. This assumes that the content of the file is encoded in UTF-8.\n","print(f\"Length of text: {len(text)} characters\") #number of characters in the string text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r3zcJkXQuHgA","executionInfo":{"status":"ok","timestamp":1706096431369,"user_tz":-330,"elapsed":64,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"f4a645cf-b144-4d86-b3fc-8e0f497e3e47"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of text: 1115394 characters\n"]}]},{"cell_type":"code","source":["#first 250 characters\n","print(text[:250])\n","print(\"----------------------------\")\n","#num of unique characters in the content\n","vocab = sorted(set(text))\n","print(f\"{len(vocab)} unique characters\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e0WOfJMvuJgX","executionInfo":{"status":"ok","timestamp":1706096431369,"user_tz":-330,"elapsed":49,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"b3b1b482-dc5e-4d87-eb54-c73dd1a16fe0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","----------------------------\n","65 unique characters\n"]}]},{"cell_type":"markdown","source":["**PROCESS THE TEXT**"],"metadata":{"id":"um0LusIBuQ_h"}},{"cell_type":"markdown","source":["VECTORIZE THE TEXT"],"metadata":{"id":"G3TQHAJ3uVW2"}},{"cell_type":"markdown","source":["*converting the strings to a numerical representation.*\n","*vectorize text data using TensorFlow's StringLookup layer. It converts strings into numeric representations, allowing for easier processing in a machine learning model.*\n"],"metadata":{"id":"flWHauCpuXnN"}},{"cell_type":"code","source":["example_texts = [\"abcdefg\", \"xyz\"]\n","chars = tf.strings.unicode_split(example_texts, input_encoding=\"UTF-8\") #splits Unicode strings into tokens\n","chars"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LCs8OSx3uZ8m","executionInfo":{"status":"ok","timestamp":1706096433247,"user_tz":-330,"elapsed":1920,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"ce9a049b-20b3-4024-9f88-c8366be0c320"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#Creating StringLookup Layer for Token-to-ID Conversion\n","ids_from_chars = tf.keras.layers.StringLookup(       #mapping string(token) to integer IDs\n","    vocabulary=list(vocab), mask_token=None    # list of unique tokens present in text, also #not mask token is used\n",")"],"metadata":{"id":"OFwuzUoDuc7R","executionInfo":{"status":"ok","timestamp":1706096433249,"user_tz":-330,"elapsed":109,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#converting tokens to character IDs\n","ids = ids_from_chars(chars)  # 'ids_from_chars' layer"],"metadata":{"id":"EJRMR6ePue4Q","executionInfo":{"status":"ok","timestamp":1706096433249,"user_tz":-330,"elapsed":107,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["GOAL IS TO GENERATE TEXT, THEREFORE IT IS IMPORTANT TO TURN THE CODED STUFF BACK INTO WORDS WE CAN UNDERSTAND"],"metadata":{"id":"FK7mt0DauovU"}},{"cell_type":"code","source":["#Creating StringLookup Layer for Id-to-Token Conversion\n","chars_from_ids=tf.keras.layers.StringLookup(\n","    vocabulary=ids_from_chars.get_vocabulary(),invert=True,mask_token=None\n",")"],"metadata":{"id":"uMCGTckzuiGW","executionInfo":{"status":"ok","timestamp":1706096433250,"user_tz":-330,"elapsed":107,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#converting IDs to Token\n","chars=chars_from_ids(ids)"],"metadata":{"id":"EbmEgY0XuktD","executionInfo":{"status":"ok","timestamp":1706096433250,"user_tz":-330,"elapsed":106,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["\n","#to join characters back to string  us tf.string.reduce_join\n","tf.strings.reduce_join(chars,axis=-1).numpy()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3hge5-JLumQX","executionInfo":{"status":"ok","timestamp":1706096433250,"user_tz":-330,"elapsed":104,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"81ee1fec-8f79-494c-acaa-389e419333df"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'abcdefg', b'xyz'], dtype=object)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["#Function to Convert IDs to Text\n","def text_from_ids(ids):\n","    return tf.strings.reduce_join(chars_from_ids(ids),axis=-1)"],"metadata":{"id":"b3f8-LA9utXc","executionInfo":{"status":"ok","timestamp":1706096433251,"user_tz":-330,"elapsed":100,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["*Create training examples and targets*"],"metadata":{"id":"mwNCOGTxuzyl"}},{"cell_type":"code","source":["#text to charac IDs\n","all_ids=ids_from_chars(tf.strings.unicode_split(text,\"UTF-8\"))\n"],"metadata":{"id":"WNPgR7eLuxpi","executionInfo":{"status":"ok","timestamp":1706096433251,"user_tz":-330,"elapsed":99,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#create dataset of these charac IDs\n","ids_dataset=tf.data.Dataset.from_tensor_slices(all_ids)             # 'tf.data.Dataset.from_tensor_slices'  creates a dataset of slices from a given tensor(here all ids)\n"],"metadata":{"id":"xy0ub-H5u154","executionInfo":{"status":"ok","timestamp":1706096433251,"user_tz":-330,"elapsed":98,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["for ids in ids_dataset.take(10):\n","    print(chars_from_ids(ids).numpy().decode(\"utf-8\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vAZXhKvnu4_0","executionInfo":{"status":"ok","timestamp":1706096433252,"user_tz":-330,"elapsed":98,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"fe8173b6-cd89-4f7e-d7a4-a4e5a42e5787"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["F\n","i\n","r\n","s\n","t\n"," \n","C\n","i\n","t\n","i\n"]}]},{"cell_type":"code","source":["\n","seq_length= 100 #desired length of each input sequence\n","examples_per_epoch=len(text)//(seq_length+1)  #number of examples (input sequences) that can be created from the entire text, considering the specified sequence length."],"metadata":{"id":"x_YhhXZgu9Nq","executionInfo":{"status":"ok","timestamp":1706096433252,"user_tz":-330,"elapsed":93,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["#batch method lets you easily convert these individual characters to sequences of the desired size.\n","sequences=ids_dataset.batch(seq_length + 1, drop_remainder=True)   #creates batches of length - 'seq_length + 1' and 'drop_remainder=True' ensures that the remaining elements that do not fit are dropped\n","for seq in sequences.take(1):\n","    print(chars_from_ids(seq))         # loop prints the first batch of sequences.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1zINXM-ovAgW","executionInfo":{"status":"ok","timestamp":1706096433252,"user_tz":-330,"elapsed":89,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"6178629b-7da0-4c6a-b669-083c59b37588"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n"," b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n"," b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n"," b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n"," b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n"," b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n"," b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n"," b'o' b'u' b' '], shape=(101,), dtype=string)\n"]}]},{"cell_type":"code","source":["for seq in sequences.take(5):\n","    print(text_from_ids(seq).numpy())       # first 5 batches of sequences, demonstrating how the characters are joined back into strings."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLoPT9NHvCLQ","executionInfo":{"status":"ok","timestamp":1706096433253,"user_tz":-330,"elapsed":84,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"4e40cc70-f67e-47bd-d518-029209cab0c0"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n","b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n","b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n","b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n","b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"]}]},{"cell_type":"code","source":["#for training\n","#takes a sequence as input, duplicates, and shifts it to align the input and label for each timestep\n","def split_input_target(sequence):\n","    input_text=sequence[:-1]\n","    target_text=sequence[1:]\n","    return input_text, target_text"],"metadata":{"id":"RzguJ899vEOF","executionInfo":{"status":"ok","timestamp":1706096433253,"user_tz":-330,"elapsed":79,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["split_input_target(list(\"Tensorflow\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vPkqIcCiTJV2","executionInfo":{"status":"ok","timestamp":1706096433253,"user_tz":-330,"elapsed":78,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"07446050-b9b8-4210-ec09-bc920f445178"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n"," ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["dataset= sequences.map(split_input_target)\n","# resulting dataset contains pairs of input and target sequences, where each input sequence corresponds to predicting the next character in the target sequence."],"metadata":{"id":"jNisGUnVvGGh","executionInfo":{"status":"ok","timestamp":1706096433254,"user_tz":-330,"elapsed":73,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["for input_examp, target_examp in dataset.take(1):\n","    print(\"input : \", text_from_ids(input_examp).numpy())\n","    print(\"target : \", text_from_ids(target_examp).numpy())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBhgopttvHqw","executionInfo":{"status":"ok","timestamp":1706096433254,"user_tz":-330,"elapsed":72,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"8fd2d915-8879-4d36-a28c-11b26fe5bd93"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["input :  b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n","target :  b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"]}]},{"cell_type":"code","source":["#preparing the dataset for training by shuffling the sequences, packing them into batches, and prefetching data for optimization.\n","BATCH_SIZE=64\n","BUFFER_SIZE = 10000\n","\n","dataset = (\n","    dataset.shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE)\n",")\n","\n","dataset"],"metadata":{"id":"eYuadyx9vI_Y","executionInfo":{"status":"ok","timestamp":1706096433254,"user_tz":-330,"elapsed":58,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"01584f0b-bd5a-426e-90e3-f5af88511329"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["**Build The Model**"],"metadata":{"id":"KpUzaahpvMCo"}},{"cell_type":"code","source":["vocab_size =len(vocab)\n","embedding_dim = 256    #the size of the vectors that represents the characters\n","rnn_units=1024"],"metadata":{"id":"96Q6yEXOvKOV","executionInfo":{"status":"ok","timestamp":1706096433254,"user_tz":-330,"elapsed":54,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["class MyModel(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, rnn_units):\n","        super().__init__()\n","        self.embedding=tf.keras.layers.Embedding(vocab_size,embedding_dim)\n","        self.gru = tf.keras.layers.GRU(\n","            rnn_units, return_sequences=True, return_state=True\n","        )\n","        self.dense=tf.keras.layers.Dense(vocab_size)\n","\n","    def call(self, inputs, states=None, return_state=False, training=False):\n","        x = self.embedding(inputs, training=training)\n","        if states is None:\n","            states = self.gru.get_initial_state(x)\n","        x, states = self.gru(x, initial_state=states, training=training)\n","        x = self.dense(x, training=training)\n","\n","        if return_state:\n","          return x, states\n","        else:\n","          return x"],"metadata":{"id":"TEHV5G4_vN4r","executionInfo":{"status":"ok","timestamp":1706096433255,"user_tz":-330,"elapsed":49,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["model=MyModel(\n","    vocab_size=len(ids_from_chars.get_vocabulary()),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units,\n",")"],"metadata":{"id":"1IPHi7k1vRJe","executionInfo":{"status":"ok","timestamp":1706096433255,"user_tz":-330,"elapsed":48,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["**TRYING THE MODEL**\n"],"metadata":{"id":"zjzdNB7kyUQq"}},{"cell_type":"code","source":["#checking the shape of the output\n","for input_example_batch, target_example_batch in dataset.take(1):\n","    example_batch_predictions = model(input_example_batch)\n","    print(\n","        example_batch_predictions.shape,\n","        \"# (batch_size, sequence_length, vocab_size)\",\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BlqYJWPuwq0p","executionInfo":{"status":"ok","timestamp":1706096437134,"user_tz":-330,"elapsed":3925,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"9ed53475-527d-421f-91c1-b0b9ca3c5529"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNriZE3kyk9N","executionInfo":{"status":"ok","timestamp":1706096437135,"user_tz":-330,"elapsed":74,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"77f3f058-ea01-4d35-b07c-e7e6df8630c6"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"my_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  16896     \n","                                                                 \n"," gru (GRU)                   multiple                  3938304   \n","                                                                 \n"," dense (Dense)               multiple                  67650     \n","                                                                 \n","=================================================================\n","Total params: 4022850 (15.35 MB)\n","Trainable params: 4022850 (15.35 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["sampled_indices = tf.random.categorical(\n","    example_batch_predictions[0], num_samples=1\n",")\n","sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"],"metadata":{"id":"XIEU9R-lyv6q","executionInfo":{"status":"ok","timestamp":1706096437136,"user_tz":-330,"elapsed":66,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["sampled_indices"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HozNOnobC3Mz","executionInfo":{"status":"ok","timestamp":1706096437136,"user_tz":-330,"elapsed":65,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"652fb1e3-02fe-429b-facd-e08987711a5c"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([33, 16, 30, 15, 52, 24, 63, 17, 63, 20,  0, 41, 18,  5, 12, 36, 23,\n","       45, 16, 16, 33, 20,  6, 10, 53, 21, 36, 28, 32, 52, 56, 56, 24, 33,\n","       16, 17, 62, 64, 51, 34, 63,  3, 33, 31, 20, 50,  1, 31, 24, 45, 11,\n","        1, 48, 61, 13, 26, 42, 21, 28, 37, 59, 31, 43,  9, 30, 53, 10, 12,\n","       54, 54, 34, 29, 48, 42, 34,  5, 32, 15, 49,  2, 13, 56, 55, 29, 17,\n","       38, 13, 25, 45, 23,  2, 29, 60,  3, 10, 38, 27, 49,  7, 39])"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["#prediction of next character (shows how untrained the model is)\n","print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n","print()\n","print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_4O3d4M9C5Te","executionInfo":{"status":"ok","timestamp":1706096437136,"user_tz":-330,"elapsed":60,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"87e0812d-a588-4ae7-8086-181321ea5807"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Input:\n"," b\"iers for these Irish wars.\\nCome, gentlemen, let's all go visit him:\\nPray God we may make haste, and \"\n","\n","Next Char Predictions:\n"," b\"TCQBmKxDxG[UNK]bE&;WJfCCTG'3nHWOSmqqKTCDwylUx!TRGk\\nRKf:\\niv?McHOXtRd.Qn3;ooUPicU&SBj ?qpPDY?LfJ Pu!3YNj,Z\"\n"]}]},{"cell_type":"markdown","source":["**TRAIN THE MODEL**"],"metadata":{"id":"m913zzi8DWMB"}},{"cell_type":"code","source":["#Define Loss Function\n","loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"],"metadata":{"id":"uXIKMBk5C7Zy","executionInfo":{"status":"ok","timestamp":1706096437138,"user_tz":-330,"elapsed":57,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n","print(\n","    \"Prediction shape: \",\n","    example_batch_predictions.shape,\n","    \" # (batch_size, sequence_length, vocab_size)\",\n",")\n","print(\"Mean loss:        \", example_batch_mean_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zyn2YKJVEzf3","executionInfo":{"status":"ok","timestamp":1706096437138,"user_tz":-330,"elapsed":56,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"62ac4fd9-3065-4fba-fcb6-6f9445282377"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n","Mean loss:         tf.Tensor(4.1901584, shape=(), dtype=float32)\n"]}]},{"cell_type":"code","source":["tf.exp(example_batch_mean_loss).numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KM4Z9TBuFaHl","executionInfo":{"status":"ok","timestamp":1706096437139,"user_tz":-330,"elapsed":51,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"ff4c97fa-a44d-4536-8501-c8b408d11e02"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["66.03325"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["#Configure Optimizer and Compile Model\n","model.compile(optimizer=\"adam\", loss=loss)   #Adam optimizer, a popular choice for stochastic optimization, and the specified loss function"],"metadata":{"id":"3VD333LhF3ms","executionInfo":{"status":"ok","timestamp":1706096437139,"user_tz":-330,"elapsed":46,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["\n","#to save model checkpoints during training\n","checkpoint_dir = \"./training_checkpoints\"\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix, save_weights_only=True\n",")"],"metadata":{"id":"hgoupj0CHHj4","executionInfo":{"status":"ok","timestamp":1706096437139,"user_tz":-330,"elapsed":45,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["#execute training\n","EPOCHS=30"],"metadata":{"id":"R_LYsGv3KRql","executionInfo":{"status":"ok","timestamp":1706096437139,"user_tz":-330,"elapsed":44,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iteAeF-WVAk6","executionInfo":{"status":"ok","timestamp":1706096917971,"user_tz":-330,"elapsed":480876,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"5b07c511-8a54-43c5-f721-ba520cbb0820"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","172/172 [==============================] - 16s 65ms/step - loss: 2.7081\n","Epoch 2/30\n","172/172 [==============================] - 14s 58ms/step - loss: 1.9735\n","Epoch 3/30\n","172/172 [==============================] - 12s 60ms/step - loss: 1.6967\n","Epoch 4/30\n","172/172 [==============================] - 13s 62ms/step - loss: 1.5397\n","Epoch 5/30\n","172/172 [==============================] - 12s 62ms/step - loss: 1.4435\n","Epoch 6/30\n","172/172 [==============================] - 12s 61ms/step - loss: 1.3773\n","Epoch 7/30\n","172/172 [==============================] - 12s 61ms/step - loss: 1.3259\n","Epoch 8/30\n","172/172 [==============================] - 12s 61ms/step - loss: 1.2805\n","Epoch 9/30\n","172/172 [==============================] - 12s 61ms/step - loss: 1.2390\n","Epoch 10/30\n","172/172 [==============================] - 12s 62ms/step - loss: 1.1979\n","Epoch 11/30\n","172/172 [==============================] - 12s 61ms/step - loss: 1.1572\n","Epoch 12/30\n","172/172 [==============================] - 12s 62ms/step - loss: 1.1139\n","Epoch 13/30\n","172/172 [==============================] - 13s 62ms/step - loss: 1.0695\n","Epoch 14/30\n","172/172 [==============================] - 13s 61ms/step - loss: 1.0223\n","Epoch 15/30\n","172/172 [==============================] - 12s 61ms/step - loss: 0.9721\n","Epoch 16/30\n","172/172 [==============================] - 12s 61ms/step - loss: 0.9199\n","Epoch 17/30\n","172/172 [==============================] - 12s 62ms/step - loss: 0.8652\n","Epoch 18/30\n","172/172 [==============================] - 12s 61ms/step - loss: 0.8120\n","Epoch 19/30\n","172/172 [==============================] - 12s 61ms/step - loss: 0.7605\n","Epoch 20/30\n","172/172 [==============================] - 12s 61ms/step - loss: 0.7128\n","Epoch 21/30\n","172/172 [==============================] - 12s 62ms/step - loss: 0.6687\n","Epoch 22/30\n","172/172 [==============================] - 12s 61ms/step - loss: 0.6303\n","Epoch 23/30\n","172/172 [==============================] - 12s 61ms/step - loss: 0.5954\n","Epoch 24/30\n","172/172 [==============================] - 12s 61ms/step - loss: 0.5670\n","Epoch 25/30\n","172/172 [==============================] - 13s 62ms/step - loss: 0.5428\n","Epoch 26/30\n","172/172 [==============================] - 13s 62ms/step - loss: 0.5216\n","Epoch 27/30\n","172/172 [==============================] - 12s 61ms/step - loss: 0.5045\n","Epoch 28/30\n","172/172 [==============================] - 12s 61ms/step - loss: 0.4905\n","Epoch 29/30\n","172/172 [==============================] - 12s 62ms/step - loss: 0.4794\n","Epoch 30/30\n","172/172 [==============================] - 12s 61ms/step - loss: 0.4672\n"]}]},{"cell_type":"markdown","source":["**GENERATE TEXT using the trained text generation model**\n"],"metadata":{"id":"mxPywQYgMK3w"}},{"cell_type":"code","source":["class OneStep(tf.keras.Model):\n","    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n","        super().__init__()\n","        self.temperature = temperature\n","        self.model = model\n","        self.chars_from_ids = chars_from_ids\n","        self.ids_from_chars = ids_from_chars\n","        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n","        sparse_mask = tf.SparseTensor(\n","            values=[-float(\"inf\")] * len(skip_ids),\n","            indices=skip_ids,\n","            dense_shape=[len(ids_from_chars.get_vocabulary())],\n","        )\n","        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n","\n","    @tf.function\n","    def generate_one_step(self, inputs, states=None):\n","        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n","        input_ids = self.ids_from_chars(input_chars).to_tensor()\n","        # input_ids = tf.expand_dims(input_ids, axis=0)\n","        # if states is None:\n","        #   states = [tf.zeros([1, self.model.gru.units])]\n","        predicted_logits, states = self.model(\n","            inputs=input_ids, states=states, return_state=True\n","            )\n","        predicted_logits = predicted_logits[:, -1, :]\n","        predicted_logits = predicted_logits / self.temperature\n","        predicted_logits = predicted_logits + self.prediction_mask\n","        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","        predicted_chars = self.chars_from_ids(predicted_ids)\n","        return predicted_chars, states"],"metadata":{"id":"_3YNf_sdiPcl","executionInfo":{"status":"ok","timestamp":1706096917971,"user_tz":-330,"elapsed":26,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"],"metadata":{"id":"yLAYDZ6Vdba6","executionInfo":{"status":"ok","timestamp":1706096917971,"user_tz":-330,"elapsed":8,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["start = time.time()\n","states = None\n","next_char = tf.constant([\"ROMEO:\"])\n","result = [next_char]\n","\n","for n in range(1000):\n","    next_char, states = one_step_model.generate_one_step(\n","        next_char, states=states\n","    )\n","    result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode(\"utf-8\"), \"\\n\\n\" + \"_\" * 80)\n","print(\"\\nRun time:\", end - start)"],"metadata":{"id":"MUjvT8gDSfWa","executionInfo":{"status":"ok","timestamp":1706096921129,"user_tz":-330,"elapsed":3165,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9d8c6f16-cda1-4397-f9a9-5350e1cfac8a"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["ROMEO:\n","These greatful mother then will I my daughter?\n","\n","BIONDELLO:\n","No.\n","\n","Third Servingman:\n","Where is he?\n","\n","CURTIS:\n","They are life better.\n","\n","HASTINGS:\n","The queen with slooking souls,\n","And scared my duty were you make,\n","Which way it to curse the city.\n","\n","BRUTUS:\n","We should bo else\n","I thought it was so fair a servant of incelstant\n","And learning in but for the truth o' the common early,\n","I should possess you. You mean a gross:\n","Colse throne, on ey; and for even near\n","No reap' thus spoil;\n","'Tis those confusions.\n","\n","LUCIO:\n","Right.\n","\n","DUKE VINCENTIO:\n","Bishop, 'twixt what is yours,\n","For the most murm revenge that Were wear it\n","In eyes, with honey, shore! why, then, thou slew me\n","To such this spartle grief hath done.\n","For the fair done, by right once more than you\n","Have caused him to the execution.\n","\n","BRUTUS:\n","Not inquite; away.\n","\n","DUKE VINCENTIO:\n","You should acconceive your vantage,\n","The common lie that it must beat down their deeds.\n","\n","WARWICK:\n","Thus by not heir to hear of thee thee, friend\n","Anon, my lord. And then to give him home for w \n","\n","________________________________________________________________________________\n","\n","Run time: 3.0404720306396484\n"]}]},{"cell_type":"code","source":["start = time.time()\n","states = None\n","next_char = tf.constant([\"ROMEO:\", \"ROMEO:\", \"ROMEO:\", \"ROMEO:\", \"ROMEO:\"])\n","result = [next_char]\n","\n","for n in range(1000):\n","    next_char, states = one_step_model.generate_one_step(\n","        next_char, states=states\n","    )\n","    result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result, \"\\n\\n\" + \"_\" * 80)\n","print(\"\\nRun time:\", end - start)"],"metadata":{"id":"TzhJFE1ExtUw","executionInfo":{"status":"ok","timestamp":1706098208264,"user_tz":-330,"elapsed":3503,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a677e613-5c48-470e-9e2e-67e2eb4bff4d"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[b\"ROMEO:\\nThe honourable father was the lieutenant\\nFrom handing to be winter in:\\nO, ighis prayers partly survain.\\n\\nLUCIO:\\nWell, no more of him, that have you are our barring.\\n\\nServant:\\nYou have a spirit! Would all the world abuse,\\nExemeth in jest. Hark, hark! I am not brow and say 'Ala's lie\\nHis love with you: but yet I'll profess to me.\\nI do fair, sweet both are a king, and perjure\\nHis name is manner, in the divines of ske\\nThat you might well for commoun's aid;\\nBut look'd for here, I have determined steep Than my son,\\nWe'll dispersed them awhile: he shall between like him;\\nMy love the heavens go sweet for his count.\\n\\nFirst Citizen:\\nYour will be deliver'd, I warrant, an I go;\\nNor is a dear actlempo, we are full of ourselves;\\nHer words reeving more than the service's wounds.\\nO, he is lost between, as we have causer'd to be\\nwhat raimed in your orce to part.\\n\\nPETRUCHIO:\\nWhy, sir, I would not dare; but looks too light.\\nDown, what mayor is with such a care,\\nToward the secons-witted enemy\\nhe'll bark \"\n"," b\"ROMEO:\\nThy father lady came to her youth? we'll have no beggar.\\nWhat, wilt thou not? there? have not it baneful eyes.\\n\\nNurse:\\nAy, with him hence.\\n\\nROMEO:\\nIs it even so? did us that offence\\nThat honourable dog thyse fancy.\\n\\nQUEEN MARGARET:\\nWhy, how now! What, good many omething earl of spring!\\nHis rebemberland arms his new sweet lady spirit\\nAgainst my hate, do stand conquern'd at.\\n\\nQUEEN ELIZABETH:\\nWhat I have? Well, we heard thee with thy hand,\\nThou art inclined to sleep. What's this?\\n\\nJULIET:\\nMadam, I'll die with trembling art those who,\\nhath virtuous with decreaness, breasts:\\nThere is my house with no man hear of her.\\n\\nQUEEN ELIZABETH:\\nBe absolved to my house and such deep as\\nYou higher my numbind of her,\\n'Tis he torment me.\\nA Edimitic, what dojest it!\\nShe may you both my love and few'st--throw unwholes\\nmay be at many things as heavy-land and\\nIncestall that have mine honishing,\\nI think it would not harm about my death,\\nAnd how his brother Clarence too, the wisod summer's heirs,\\nO, now bles\"\n"," b\"ROMEO:\\nWell, let me see her: or how are you married;\\nThat brought forth all night-speak of it?\\nThy heapt is a traitorn back, and leave us long.\\nIs't not Herryie close in tune? a horse!\\n\\nHARTINGS:\\nA deed will I will follow. Well, I doubt not\\nThe most releable and my prophecies,\\nTrained nor hast not the common bands of liberty.\\n\\nVINCENTIO:\\nWhen you have well enough?\\n\\nSecond Senator:\\nSo hurt in heaven and all bost woe,\\nAnd I'll stir with thee even to the present,\\nOr that he is a dream to-night.\\n\\nEDWARD:\\nNo, joy! Where's CameLet is yond, move longues,\\nOn whote no measure. What, here's\\nMy business use that is right wint.\\n\\nQUEEN MARGARET:\\nThanks, gentle Soil!\\nOnce more, I see Fortune with the triumph;\\nWithal, what shouts are these?\\n\\nTHOMAS MOWBRAY:\\nRight gently, you want not that you may, but slew them\\nAs thou hast breed a curse. But this I'll bail them:\\n'videward more, farewell.\\n\\nGEORG:\\nAnd but the king did rute my tale brother?\\nThe exchange of our devousings and heaviers nirmment bodes:\\nBearing \"\n"," b\"ROMEO:\\nO pried, God! what made thee A murderer,\\nI'll pray him fresh as e'er warms, and twenty plocks.\\nNow they follow me, grander those days\\nAnd neither object times my woe shall need;\\nBut what shall become of solemness and scope,\\nWhich she longer then our sea-side.\\nHie to her heavy will,\\nAnd warried the envy you thereof,\\nsoject and received an oath wind shade,\\nTo have the heir of the Lord Augelous eyes\\nWith twenty humour with slander thereof,\\nSo two his foother triumphsman's;\\nAnd that thou art not have but dream'd a few to you:\\nCome hither, 'fore me, his unbot'st and accidenence\\nThough we suppose, that he didst venture to give\\nhis father; and, in human afternoon\\nThis shall be my bone, that you migging,\\nMore man that Loopest too, but a kind or breath?\\n\\nKING EDWARD IV:\\nYea, noble uncle York, and himself,\\nNone else be led his head; the shrews of her own life;\\nMy husband cushions be absent: sir,\\nwith her consis; you know the cords.\\n\\nCOMINIUS:\\nCome, come, we'll promise be: for they\\nare comings i\"\n"," b\"ROMEO:\\nThe younger pates on her give you? what's the way?\\n\\nDUKE VINCENTIO:\\nThen will my tongue from our foeth, that think you\\nOf this sweet sister to my soul,\\nInto am comfort, whose every motion makes\\nThat scapes and women are froward.\\n\\nRIVEY:\\nI told you. Woter arm, and in this case to beat\\nAs if he goes to put your steed.\\n\\nFLORIZEL:\\nO more, must go.\\n\\nDUKE OF AUMERLE:\\nBy the cap-quee of my mistress, wert thou not hear\\nThe pleasant tarry, with twenty thousand crowns,\\nI cannot fail. This your companion that I would know,\\nThat, rubaus to you; therefore I'll owe\\nEither of you to do him rish, and have hearts\\nWith sighs; the order is the wall: if\\nhe terrible hither would that banished\\nWhen it doth todm the spirits Hastings?\\n\\nBRUTUS:\\nSee, wherefore hast whose names are mine?\\n\\nPETRUCHIO:\\nWhat? lass of some little toich?\\n\\nBAPTISTA:\\nWhy, then I wish this shall you he'll prove as triff;\\nI am too quickly quit with this friend,\\nCome to your senate, I'll deliver so force.\\nWhat, wilt thee is your highness \"], shape=(5,), dtype=string) \n","\n","________________________________________________________________________________\n","\n","Run time: 3.0434374809265137\n"]}]},{"cell_type":"markdown","source":["**EXPORT THE GENERATOR**"],"metadata":{"id":"lgreA5BeYUBo"}},{"cell_type":"code","source":["tf.saved_model.save(one_step_model, \"one_step\") #model will be saved as a TensorFlow SavedModel\n","one_step_reloaded = tf.saved_model.load(\"one_step\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mqGPyutSRV21","executionInfo":{"status":"ok","timestamp":1706098406010,"user_tz":-330,"elapsed":5640,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"68c08abd-ec93-4fd2-aa2a-24453ed8303d"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x790b0219aaa0>, because it is not built.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"]}]},{"cell_type":"code","source":["#Generating Text with Reloaded Model\n","states = None\n","next_char = tf.constant([\"ROMEO:\"])\n","result = [next_char]\n","\n","for n in range(100):\n","    next_char, states = one_step_reloaded.generate_one_step(\n","        next_char, states=states\n","    )\n","    result.append(next_char)\n","print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7_NEz1KYz91","executionInfo":{"status":"ok","timestamp":1706098451588,"user_tz":-330,"elapsed":1142,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"731ee2c2-c00e-4d51-e186-d49aa63d4ab1"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["ROMEO:\n","The foe is it to be the master, Pompey,\n","And yet plucked dangerously, to bearing one\n","change garments\n"]}]},{"cell_type":"markdown","source":["**custom training loop for a character-level text generation model**"],"metadata":{"id":"RpWqWIHxhSVi"}},{"cell_type":"code","source":["#CustomTraining Class\n","class CustomTraining(MyModel):\n","    @tf.function\n","    def train_step(self, inputs):\n","        inputs, labels = inputs\n","        with tf.GradientTape() as tape:\n","            predictions = self(inputs, training=True)\n","            loss = self.loss(labels, predictions)\n","        grads = tape.gradient(loss, model.trainable_variables)\n","        self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","        return {\"loss\": loss}"],"metadata":{"id":"Ima0mQ-9hQpW","executionInfo":{"status":"ok","timestamp":1706100671943,"user_tz":-330,"elapsed":465,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["#model is instantiated and compiled using the Adam optimizer and SparseCategoricalCrossentropy loss\n","model = CustomTraining(\n","    vocab_size=len(ids_from_chars.get_vocabulary()),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units,\n",")\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(),\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",")"],"metadata":{"id":"6TWOkVbNhkE2","executionInfo":{"status":"ok","timestamp":1706100682756,"user_tz":-330,"elapsed":458,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["#Training Loop\n","EPOCHS = 10\n","mean = tf.metrics.Mean()\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    mean.reset_states()\n","    for batch_n, (inp, target) in enumerate(dataset):\n","        logs = model.train_step([inp, target])\n","        mean.update_state(logs[\"loss\"])\n","\n","        if batch_n % 50 == 0:\n","            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n","            print(template)\n","\n","    # saving (checkpoint) the model every 5 epochs\n","    if (epoch + 1) % 5 == 0:\n","        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n","\n","    print()\n","    print(f\"Epoch {epoch+1} Loss: {mean.result().numpy():.4f}\")\n","    print(f\"Time taken for 1 epoch {time.time() - start:.2f} sec\")\n","    print(\"_\" * 80)\n","\n","model.save_weights(checkpoint_prefix.format(epoch=epoch))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_GgZgGohmrn","executionInfo":{"status":"ok","timestamp":1706100835629,"user_tz":-330,"elapsed":130953,"user":{"displayName":"Yuzia Haque","userId":"17224139340577652223"}},"outputId":"66da2df0-5ebc-45b4-cd34-5cb88d7c5d83"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0 Loss 4.1904\n","Epoch 1 Batch 50 Loss 2.8996\n","Epoch 1 Batch 100 Loss 2.3812\n","Epoch 1 Batch 150 Loss 2.2214\n","\n","Epoch 1 Loss: 2.7247\n","Time taken for 1 epoch 14.45 sec\n","________________________________________________________________________________\n","Epoch 2 Batch 0 Loss 2.1862\n","Epoch 2 Batch 50 Loss 2.0688\n","Epoch 2 Batch 100 Loss 1.9430\n","Epoch 2 Batch 150 Loss 1.8758\n","\n","Epoch 2 Loss: 1.9905\n","Time taken for 1 epoch 11.06 sec\n","________________________________________________________________________________\n","Epoch 3 Batch 0 Loss 1.7957\n","Epoch 3 Batch 50 Loss 1.7606\n","Epoch 3 Batch 100 Loss 1.6900\n","Epoch 3 Batch 150 Loss 1.6121\n","\n","Epoch 3 Loss: 1.7115\n","Time taken for 1 epoch 20.47 sec\n","________________________________________________________________________________\n","Epoch 4 Batch 0 Loss 1.6160\n","Epoch 4 Batch 50 Loss 1.5602\n","Epoch 4 Batch 100 Loss 1.5263\n","Epoch 4 Batch 150 Loss 1.5543\n","\n","Epoch 4 Loss: 1.5489\n","Time taken for 1 epoch 11.81 sec\n","________________________________________________________________________________\n","Epoch 5 Batch 0 Loss 1.4623\n","Epoch 5 Batch 50 Loss 1.4682\n","Epoch 5 Batch 100 Loss 1.4708\n","Epoch 5 Batch 150 Loss 1.4371\n","\n","Epoch 5 Loss: 1.4503\n","Time taken for 1 epoch 12.14 sec\n","________________________________________________________________________________\n","Epoch 6 Batch 0 Loss 1.3692\n","Epoch 6 Batch 50 Loss 1.3758\n","Epoch 6 Batch 100 Loss 1.3973\n","Epoch 6 Batch 150 Loss 1.3861\n","\n","Epoch 6 Loss: 1.3810\n","Time taken for 1 epoch 12.68 sec\n","________________________________________________________________________________\n","Epoch 7 Batch 0 Loss 1.3451\n","Epoch 7 Batch 50 Loss 1.2998\n","Epoch 7 Batch 100 Loss 1.3559\n","Epoch 7 Batch 150 Loss 1.3003\n","\n","Epoch 7 Loss: 1.3285\n","Time taken for 1 epoch 12.11 sec\n","________________________________________________________________________________\n","Epoch 8 Batch 0 Loss 1.2698\n","Epoch 8 Batch 50 Loss 1.2466\n","Epoch 8 Batch 100 Loss 1.3106\n","Epoch 8 Batch 150 Loss 1.2793\n","\n","Epoch 8 Loss: 1.2823\n","Time taken for 1 epoch 12.01 sec\n","________________________________________________________________________________\n","Epoch 9 Batch 0 Loss 1.2188\n","Epoch 9 Batch 50 Loss 1.1997\n","Epoch 9 Batch 100 Loss 1.2379\n","Epoch 9 Batch 150 Loss 1.3038\n","\n","Epoch 9 Loss: 1.2417\n","Time taken for 1 epoch 11.78 sec\n","________________________________________________________________________________\n","Epoch 10 Batch 0 Loss 1.1917\n","Epoch 10 Batch 50 Loss 1.1808\n","Epoch 10 Batch 100 Loss 1.1909\n","Epoch 10 Batch 150 Loss 1.2347\n","\n","Epoch 10 Loss: 1.2007\n","Time taken for 1 epoch 11.91 sec\n","________________________________________________________________________________\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1sI4Yh_RhsK-"},"execution_count":null,"outputs":[]}]}